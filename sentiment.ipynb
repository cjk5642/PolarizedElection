{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re, string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "stop_words = stopwords.words('english')\n",
    "#keep words that may contribute to sentiment \n",
    "stop_words.pop(stop_words.index('no'))\n",
    "stop_words.pop(stop_words.index('not'))\n",
    "stop_words.pop(stop_words.index('against'))\n",
    "stop_words.pop(stop_words.index(\"couldn't\"))\n",
    "stop_words.pop(stop_words.index(\"aren't\"))\n",
    "stop_words.pop(stop_words.index(\"won't\"))\n",
    "            \n",
    "def read_jsonl(filename):\n",
    "    '''Iterates through a JSONL file'''\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line.rstrip('\\n|\\r'))\n",
    "            \n",
    "\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "    '''\n",
    "    Cleans the tweet tokens, removing links and special characters,\n",
    "    tags part of speech of words, and lemmatizes\n",
    "    '''\n",
    "    cleaned_tokens = []\n",
    "    myre = re.compile(u'['\n",
    "    u'\\U0001F300-\\U0001F64F'\n",
    "    u'\\U0001F680-\\U0001F6FF'\n",
    "    u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "    re.UNICODE)\n",
    "    \n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "        token = myre.sub('',token)\n",
    "        token = token.replace('‚Äú','').replace('‚Äù','').replace('‚Ä¶','')\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRTWorldNow</td>\n",
       "      <td>Istanbul, Turkey</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>us president donald trump rival candidate joe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VicOlsenHolt</td>\n",
       "      <td>United States</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>great ad #watch #pennsylvania #michigan #flori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artistwhogives</td>\n",
       "      <td>Headingley, Leeds, UK</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dumpy donnie candidate rioter looter arsonist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BevAzevedo</td>\n",
       "      <td>Canada</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>time come #vote #election2020 #raiseyourvoice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benpowell321</td>\n",
       "      <td>Singapore</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>blackrock investment institute update global o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36379</th>\n",
       "      <td>latinojustice</td>\n",
       "      <td>New York</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>#cadavotocuenta volunteer #ga make sure commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36380</th>\n",
       "      <td>RebekahWriter</td>\n",
       "      <td>Maryland</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>got plan 11/3 no worried idea #election2020 #e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36381</th>\n",
       "      <td>MxdWrstlgAsscNY</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>vote matter make voting plan #election2020 fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36382</th>\n",
       "      <td>CSAC_Counties</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>vote add voice chorus form opinion basis actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36383</th>\n",
       "      <td>FYNTV</td>\n",
       "      <td>Ellijay, GA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>wake w all-star political panel live every fri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36384 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username               location longitude latitude  \\\n",
       "0          TRTWorldNow       Istanbul, Turkey                      \n",
       "1         VicOlsenHolt          United States                      \n",
       "2       Artistwhogives  Headingley, Leeds, UK                      \n",
       "3           BevAzevedo                 Canada                      \n",
       "4         benpowell321             Singapore                       \n",
       "...                ...                    ...       ...      ...   \n",
       "36379    latinojustice               New York                      \n",
       "36380    RebekahWriter               Maryland                      \n",
       "36381  MxdWrstlgAsscNY          New York, USA                      \n",
       "36382    CSAC_Counties             Sacramento                      \n",
       "36383            FYNTV            Ellijay, GA                      \n",
       "\n",
       "                                                  tweets  \n",
       "0      us president donald trump rival candidate joe ...  \n",
       "1      great ad #watch #pennsylvania #michigan #flori...  \n",
       "2      dumpy donnie candidate rioter looter arsonist ...  \n",
       "3      time come #vote #election2020 #raiseyourvoice ...  \n",
       "4      blackrock investment institute update global o...  \n",
       "...                                                  ...  \n",
       "36379  #cadavotocuenta volunteer #ga make sure commun...  \n",
       "36380  got plan 11/3 no worried idea #election2020 #e...  \n",
       "36381  vote matter make voting plan #election2020 fin...  \n",
       "36382  vote add voice chorus form opinion basis actio...  \n",
       "36383  wake w all-star political panel live every fri...  \n",
       "\n",
       "[36384 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = pd.DataFrame(columns = ['username','location','longitude','latitude','tweets'])\n",
    "\n",
    "### Reading tweet data from json file\n",
    "datareader = read_jsonl('election_filter_10-26_10-29.jsonl')\n",
    "\n",
    "count = 0\n",
    "for tweet in datareader:\n",
    "    if tweet['location'] != '':\n",
    "        count += 1\n",
    "        # Read in data and preprocess\n",
    "        text = tweet['text']\n",
    "        name = tweet['username']\n",
    "        loc = tweet['location']\n",
    "        long = tweet['longitude']\n",
    "        lat = tweet['latitude']\n",
    "        tokenized_tweet = tokenizer.tokenize(text)\n",
    "        cleaned_text = remove_noise(tokenized_tweet, stop_words)\n",
    "        cleaned_text = ' '.join(cleaned_text)\n",
    "        data = {'username':name, 'location': loc, 'longitude':long, 'latitude':lat, 'tweets':cleaned_text}\n",
    "        all_data = all_data.append(data, ignore_index = True)\n",
    "        \n",
    "        #if count == 100:\n",
    "        #    break\n",
    "    \n",
    "display(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>NumTweets</th>\n",
       "      <th>DemTweets</th>\n",
       "      <th>RepTweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000HMY</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>[#democracy life #vote #maga not #trump realit...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#democracy life #vote #maga not #trump realit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02deebo</td>\n",
       "      <td>Oregon, USA</td>\n",
       "      <td>[something #trump truly take credit #trumplied...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[something #trump truly take credit #trumplied...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09072021</td>\n",
       "      <td>Close to Lincoln‚Äôs dead bodyüëª</td>\n",
       "      <td>[one reason #trump many devoted supporter ‚¨á Ô∏è ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[one reason #trump many devoted supporter ‚¨á Ô∏è ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0bzerve</td>\n",
       "      <td>Kentucky, USA</td>\n",
       "      <td>[‚Äô #biden campaign bus travel good security li...</td>\n",
       "      <td>1</td>\n",
       "      <td>[‚Äô #biden campaign bus travel good security li...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ldManStoneZone</td>\n",
       "      <td>SOMEüå¥BEACHüåÖSOMEüë£WHERE‚ù§</td>\n",
       "      <td>[#biden joe mind even work no mo #voteredtosav...</td>\n",
       "      <td>3</td>\n",
       "      <td>[#biden joe mind even work no mo #voteredtosav...</td>\n",
       "      <td>[get new trump bumper sticker nice huh #votere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                       location  \\\n",
       "0           000HMY                  Las Vegas, NV   \n",
       "1          02deebo                    Oregon, USA   \n",
       "2         09072021  Close to Lincoln‚Äôs dead bodyüëª   \n",
       "3          0bzerve                  Kentucky, USA   \n",
       "4  0ldManStoneZone         SOMEüå¥BEACHüåÖSOMEüë£WHERE‚ù§   \n",
       "\n",
       "                                          all_tweets  NumTweets  \\\n",
       "0  [#democracy life #vote #maga not #trump realit...          5   \n",
       "1  [something #trump truly take credit #trumplied...          1   \n",
       "2  [one reason #trump many devoted supporter ‚¨á Ô∏è ...          1   \n",
       "3  [‚Äô #biden campaign bus travel good security li...          1   \n",
       "4  [#biden joe mind even work no mo #voteredtosav...          3   \n",
       "\n",
       "                                           DemTweets  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [‚Äô #biden campaign bus travel good security li...   \n",
       "4  [#biden joe mind even work no mo #voteredtosav...   \n",
       "\n",
       "                                           RepTweets  \n",
       "0  [#democracy life #vote #maga not #trump realit...  \n",
       "1  [something #trump truly take credit #trumplied...  \n",
       "2  [one reason #trump many devoted supporter ‚¨á Ô∏è ...  \n",
       "3                                                 []  \n",
       "4  [get new trump bumper sticker nice huh #votere...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13009\n"
     ]
    }
   ],
   "source": [
    "compiled = all_data.groupby(['username','location'])['tweets'].apply(list).reset_index(name='all_tweets')\n",
    "dem_tweets = dict()\n",
    "rep_tweets = dict()\n",
    "for row in range(len(compiled)):\n",
    "    tweets = compiled.iloc[row,-1]\n",
    "    dem_tweets[row] = []\n",
    "    rep_tweets[row] = []\n",
    "    for t in range(len(tweets)):\n",
    "        if 'biden' in tweets[t] or 'kamala' in tweets[t] or 'harris' in tweets[t]:\n",
    "            dem_tweets[row].append(tweets[t])\n",
    "        if 'trump' in tweets[t] or 'pence' in tweets[t]:\n",
    "            rep_tweets[row].append(tweets[t])\n",
    "            \n",
    "compiled['NumTweets'] = compiled['all_tweets'].apply(len)\n",
    "compiled['DemTweets'] = list(dem_tweets.values())\n",
    "compiled['RepTweets'] = list(rep_tweets.values())\n",
    "compiled = compiled.reset_index(drop=True)\n",
    "# drop if both tweets have empty lists\n",
    "indicies = []\n",
    "indicies = [row for row in range(len(compiled)) if len(compiled.iloc[row,-2]) == 0 and len(compiled.iloc[row,-1]) == 0]\n",
    "compiled = compiled.drop(indicies).reset_index(drop=True)\n",
    "display(compiled.head())\n",
    "print(len(compiled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Dist. of Columbia', 'Florida', 'Georgia', 'Guam', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Virgin Islands', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming', 'Ala.', 'Alaska', 'Ariz.', 'Ark.', 'Calif.', 'Colo.', 'Conn.', 'Del.', 'D.C.', 'Fla.', 'Ga.', 'Guam', 'Hawaii', 'Idaho', 'Ill.', 'Ind.', 'Iowa', 'Kans.', 'Ky.', 'La.', 'Maine', 'Md.', 'Mass.', 'Mich.', 'Minn.', 'Miss.', 'Mo.', 'Mont.', 'Nebr.', 'Nev.', 'N.H.', 'N.J.', 'N.M.', 'N.Y.', 'N.C.', 'N.D.', 'Ohio', 'Okla.', 'Ore.', 'Pa.', 'P.R.', 'R.I.', 'S.C.', 'S.D.', 'Tenn.', 'Tex.', 'Utah', 'Vt.', 'Va.', 'V.I.', 'Wash.', 'W.Va.', 'Wis.', 'Wyo.', 'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'GU', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'VI', 'WA', 'WV', 'WI', 'WY']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Postalcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Ala.</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Ariz.</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Ark.</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>Calif.</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Abbreviation Postalcode\n",
       "0     Alabama         Ala.         AL\n",
       "1      Alaska       Alaska         AK\n",
       "3     Arizona        Ariz.         AZ\n",
       "4    Arkansas         Ark.         AR\n",
       "5  California       Calif.         CA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states = pd.read_csv('.\\Data\\Misc\\states.csv')\n",
    "states = states.dropna(axis = 0)\n",
    "collected = [states.iloc[row, name] for name in range(len(states.columns)) for row in range(len(states))]\n",
    "print(collected)\n",
    "display(states.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
